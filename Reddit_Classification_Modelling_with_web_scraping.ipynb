{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Using Reddit's API for Predicting Subreddit Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
   },
   "source": [
    "### Scraping Thread Info from Reddit.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### importing requests, json packages for webscrapping\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### subreddits of interest\n",
    "URL1 = \"http://www.reddit.com/r/fakehistoryporn.json\"\n",
    "URL2 = \"http://www.reddit.com/r/NatureIsFuckingLit.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "### Checking HTTP status code, if good to go - 200 means good\n",
    "res1 = requests.get(URL1, headers={'User-agent': 'Abhi Bot 0.1'})\n",
    "res2 = requests.get(URL2, headers={'User-agent': 'Abhi Bot 0.2'})\n",
    "print(res1)\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Initializing the unstructured data\n",
    "# data1 = res1.json()\n",
    "# data2 = res2.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Exploring the unstructured data\n",
    "# print(sorted(data1.keys()))\n",
    "# print(sorted(data2.keys()))\n",
    "# print(sorted(data1['data'].keys()))\n",
    "# print(sorted(data2['data'].keys()))\n",
    "# print(sorted(data1['data']['children'][1]['data'].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subreddit1 - fakehistoryporn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Scrapping->Pandas->CSV for fakehistoryporn\n",
    "# import time\n",
    "# url = \"http://www.reddit.com/r/fakehistoryporn.json\"\n",
    "# all_posts =[]\n",
    "# for _ in range(30): \n",
    "#     # construct a list of 1000\n",
    "    \n",
    "#     # Get the posts by hitting the url, put it in json and store it\n",
    "#     res1 = requests.get(url, headers={'User-agent': 'boo007'})\n",
    "#     data1 = res1.json()\n",
    "    \n",
    "#     # save only the posts out of the json into the list_of_posts, then\n",
    "#     # add all the posts to the all_posts list\n",
    "#     list_of_posts = data1['data']['children']\n",
    "#     data1_posts = [post['data'] for post in list_of_posts]\n",
    "#     all_posts.extend(data1_posts)\n",
    "   \n",
    "#     # reassign the after to the current 'after', and then update the url to hit\n",
    "#     after = data1['data']['after']\n",
    "#     url =  'http://www.reddit.com/r/fakehistoryporn.json?after=' + after\n",
    "    \n",
    "#     # go to sleep for 3 seconds so you do not overwhelm reddit and get kicked out\n",
    "#     print('The current after: ', after)\n",
    "#     time.sleep(3)\n",
    "\n",
    "# # now put the list of lists, where which inner list is a row\n",
    "# # straight into a dataframe\n",
    "# df1 = pd.DataFrame(all_posts, columns = ['author' ,'domain' ,'num_comments' ,'score' ,'selftext' ,'subreddit' ,'title' ,'ups'])\n",
    "# df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Saving our results as a csv\n",
    "# pd.DataFrame(all_posts).to_csv('./test.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subreddit2 - NatureIsFuckingLit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Scrapping->Pandas->CSV for NatureIsFuckingLit\n",
    "# import time\n",
    "# url = \"http://www.reddit.com/r/NatureIsFuckingLit.json\"\n",
    "# all_posts2 =[]\n",
    "# for _ in range(30): \n",
    "#     # construct a list of 1000\n",
    "    \n",
    "#     # Get the posts by hitting the url, put it in json and store it\n",
    "#     res2 = requests.get(url, headers={'User-agent': 'boo007'})\n",
    "#     data2 = res2.json()\n",
    "    \n",
    "#     # save only the posts out of the json into the list_of_posts, then\n",
    "#     # add all the posts to the all_posts list\n",
    "#     list_of_posts = data2['data']['children']\n",
    "#     data2_posts = [post['data'] for post in list_of_posts]\n",
    "#     all_posts2.extend(data2_posts)\n",
    "   \n",
    "#     # reassign the after to the current 'after', and then update the url to hit\n",
    "#     after = data2['data']['after']\n",
    "#     url =  'http://www.reddit.com/r/NatureIsFuckingLit.json?after=' + after\n",
    "    \n",
    "#     # go to sleep for 3 seconds so you do not overwhelm reddit and get kicked out\n",
    "#     print('The current after: ', after)\n",
    "#     time.sleep(3)\n",
    "\n",
    "# # now put the list of lists, where which inner list is a row\n",
    "# # straight into a dataframe\n",
    "# df2 = pd.DataFrame(all_posts2,columns = ['author' ,'domain' ,'num_comments' ,'score' ,'selftext' ,'subreddit' ,'title' ,'ups'])\n",
    "# df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Saving our results as a csv\n",
    "# pd.DataFrame(all_posts2).to_csv('./test2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "db045898-1d2d-4af2-8e79-437c4c7546b4"
   },
   "source": [
    "## Importing Data and Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv('./test.csv')  #fakehistoryporn\n",
    "df2 = pd.read_csv('./test2.csv') #natureisfuckinlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dabhi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>discord.gg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fakehistoryporn</td>\n",
       "      <td>Fake History Porn now has an Discord server!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>self.fakehistoryporn</td>\n",
       "      <td>This one was a really difficult one to judge b...</td>\n",
       "      <td>fakehistoryporn</td>\n",
       "      <td>Lets get this over with; competition results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fakehistoryporn</td>\n",
       "      <td>Japan joins the axis (1940 colorised)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fakehistoryporn</td>\n",
       "      <td>Nazi Luftwaffe pilot marks his kills from the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fakehistoryporn</td>\n",
       "      <td>Kurt Cobain’s famous MTV Unplugged session (1993)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 domain                                           selftext  \\\n",
       "0            discord.gg                                                NaN   \n",
       "1  self.fakehistoryporn  This one was a really difficult one to judge b...   \n",
       "2             i.redd.it                                                NaN   \n",
       "3             i.redd.it                                                NaN   \n",
       "4             i.redd.it                                                NaN   \n",
       "\n",
       "         subreddit                                              title  \n",
       "0  fakehistoryporn       Fake History Porn now has an Discord server!  \n",
       "1  fakehistoryporn       Lets get this over with; competition results  \n",
       "2  fakehistoryporn              Japan joins the axis (1940 colorised)  \n",
       "3  fakehistoryporn  Nazi Luftwaffe pilot marks his kills from the ...  \n",
       "4  fakehistoryporn  Kurt Cobain’s famous MTV Unplugged session (1993)  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df1, df2], axis=0)\n",
    "df = pd.DataFrame(df, columns = ['domain' ,'selftext' ,'subreddit' ,'title'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1503, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "selftext    1499\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()[df.isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['selftext'] = df['selftext'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We want to predict a binary variable - class `0` for 'natureisfuckinlit' and `1` for 'fakehistoryporn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subreddit']=df['subreddit'].apply(lambda x:1 if x=='fakehistoryporn' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting our feature- X and target- y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df['title'] + df['selftext']\n",
    "y = df['subreddit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Value Counts for Balanced Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    752\n",
       "0    751\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,shuffle=True,stratify=y,random_state=42,test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP and Classification Modelling for Subreddits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the CountVectorizer and TFIDFVectorizer. The count vectorizer simply counts the word frequencies. The TFIDFvectorizer also counts word(term) frequencies but relative the document frequently. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing CountVectorizer and transforming our feature- train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4241\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvec = CountVectorizer(stop_words=\"english\")\n",
    "cvec.fit(X_train)\n",
    "print(len(cvec.get_feature_names()))\n",
    "X_train_cv = pd.DataFrame(cvec.transform(X_train).todense(),columns=cvec.get_feature_names())\n",
    "X_test_cv = pd.DataFrame(cvec.transform(X_test).todense(),columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns\n",
    "columns=cvec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1277, 4241)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226, 4241)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d"
   },
   "outputs": [],
   "source": [
    "## Importing more Packages\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression on Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.9380530973451328\n",
      "accuracy score 0.9380530973451328\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_cv, y_train)\n",
    "y_pred = lr.predict(X_test_cv)\n",
    "print('accuracy score',accuracy_score(y_test, y_pred))\n",
    "print('accuracy score',lr.score(X_test_cv, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing Keywords via Beta Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>01</th>\n",
       "      <th>03</th>\n",
       "      <th>08</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>100m</th>\n",
       "      <th>1011</th>\n",
       "      <th>1034108552758087682</th>\n",
       "      <th>...</th>\n",
       "      <th>zhangjiajie</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoomed</th>\n",
       "      <th>zoooooom</th>\n",
       "      <th>zootopia</th>\n",
       "      <th>çağırankaya</th>\n",
       "      <th>émile</th>\n",
       "      <th>état</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.061594</td>\n",
       "      <td>0.015318</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>-0.04791</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>0.101055</td>\n",
       "      <td>-0.068614</td>\n",
       "      <td>0.132381</td>\n",
       "      <td>0.240063</td>\n",
       "      <td>-0.038274</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027935</td>\n",
       "      <td>0.052937</td>\n",
       "      <td>-0.235828</td>\n",
       "      <td>-0.180699</td>\n",
       "      <td>-0.048343</td>\n",
       "      <td>-0.075797</td>\n",
       "      <td>0.200985</td>\n",
       "      <td>-0.107912</td>\n",
       "      <td>0.235324</td>\n",
       "      <td>0.329777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 4241 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        000        01        03       08        09        10       100  \\\n",
       "0  0.061594  0.015318  0.001977 -0.04791  0.001977  0.101055 -0.068614   \n",
       "\n",
       "       100m      1011  1034108552758087682    ...     zhangjiajie    zombie  \\\n",
       "0  0.132381  0.240063            -0.038274    ...       -0.027935  0.052937   \n",
       "\n",
       "        zoo      zoom    zoomed  zoooooom  zootopia  çağırankaya     émile  \\\n",
       "0 -0.235828 -0.180699 -0.048343 -0.075797  0.200985    -0.107912  0.235324   \n",
       "\n",
       "       état  \n",
       "0  0.329777  \n",
       "\n",
       "[1 rows x 4241 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_coef = pd.DataFrame(lr.coef_, columns = columns)\n",
    "lr_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>3.354420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colorized</th>\n",
       "      <td>2.999919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>circa</th>\n",
       "      <td>2.806465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>1.962373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>1.620474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>1.485514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ad</th>\n",
       "      <td>1.484365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hitler</th>\n",
       "      <td>1.342002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bc</th>\n",
       "      <td>1.328647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colourised</th>\n",
       "      <td>1.323269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>1.257275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>american</th>\n",
       "      <td>1.244626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>1.211354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>battle</th>\n",
       "      <td>1.193461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>1.139536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>1.121468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>german</th>\n",
       "      <td>1.091097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>war</th>\n",
       "      <td>1.077733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>1.049896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nazi</th>\n",
       "      <td>0.996933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>0.992333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>death</th>\n",
       "      <td>0.964447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>0.964026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>0.945781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colourized</th>\n",
       "      <td>0.936741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soldier</th>\n",
       "      <td>0.926260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roman</th>\n",
       "      <td>0.920630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>0.915450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president</th>\n",
       "      <td>0.888047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>army</th>\n",
       "      <td>0.845768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blue</th>\n",
       "      <td>-0.584365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eyes</th>\n",
       "      <td>-0.585298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shark</th>\n",
       "      <td>-0.587938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>park</th>\n",
       "      <td>-0.595226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kingfisher</th>\n",
       "      <td>-0.610456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iceland</th>\n",
       "      <td>-0.628472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lightning</th>\n",
       "      <td>-0.655094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coast</th>\n",
       "      <td>-0.656706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crab</th>\n",
       "      <td>-0.663467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>looking</th>\n",
       "      <td>-0.669246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>turtle</th>\n",
       "      <td>-0.677029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wasp</th>\n",
       "      <td>-0.686485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fish</th>\n",
       "      <td>-0.688778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>owl</th>\n",
       "      <td>-0.708559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caterpillar</th>\n",
       "      <td>-0.709318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dragonfly</th>\n",
       "      <td>-0.731418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>octopus</th>\n",
       "      <td>-0.772076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bird</th>\n",
       "      <td>-0.783448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rainbow</th>\n",
       "      <td>-0.799357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nature</th>\n",
       "      <td>-0.839692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moth</th>\n",
       "      <td>-0.851489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>-0.864559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lake</th>\n",
       "      <td>-0.869344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>-0.928552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunset</th>\n",
       "      <td>-0.977444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oc</th>\n",
       "      <td>-1.012334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baby</th>\n",
       "      <td>-1.051107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spider</th>\n",
       "      <td>-1.161925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>-1.237376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beautiful</th>\n",
       "      <td>-1.259550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4241 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0\n",
       "2018         3.354420\n",
       "colorized    2.999919\n",
       "circa        2.806465\n",
       "2017         1.962373\n",
       "1944         1.620474\n",
       "2016         1.485514\n",
       "ad           1.484365\n",
       "hitler       1.342002\n",
       "bc           1.328647\n",
       "colourised   1.323269\n",
       "1943         1.257275\n",
       "american     1.244626\n",
       "2014         1.211354\n",
       "battle       1.193461\n",
       "man          1.139536\n",
       "1945         1.121468\n",
       "german       1.091097\n",
       "war          1.077733\n",
       "1968         1.049896\n",
       "nazi         0.996933\n",
       "1939         0.992333\n",
       "death        0.964447\n",
       "1941         0.964026\n",
       "2011         0.945781\n",
       "colourized   0.936741\n",
       "soldier      0.926260\n",
       "roman        0.920630\n",
       "1991         0.915450\n",
       "president    0.888047\n",
       "army         0.845768\n",
       "...               ...\n",
       "blue        -0.584365\n",
       "eyes        -0.585298\n",
       "shark       -0.587938\n",
       "park        -0.595226\n",
       "kingfisher  -0.610456\n",
       "iceland     -0.628472\n",
       "lightning   -0.655094\n",
       "coast       -0.656706\n",
       "crab        -0.663467\n",
       "looking     -0.669246\n",
       "turtle      -0.677029\n",
       "wasp        -0.686485\n",
       "fish        -0.688778\n",
       "owl         -0.708559\n",
       "caterpillar -0.709318\n",
       "dragonfly   -0.731418\n",
       "octopus     -0.772076\n",
       "bird        -0.783448\n",
       "rainbow     -0.799357\n",
       "nature      -0.839692\n",
       "moth        -0.851489\n",
       "like        -0.864559\n",
       "lake        -0.869344\n",
       "just        -0.928552\n",
       "sunset      -0.977444\n",
       "oc          -1.012334\n",
       "baby        -1.051107\n",
       "spider      -1.161925\n",
       "tree        -1.237376\n",
       "beautiful   -1.259550\n",
       "\n",
       "[4241 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coef = lr_coef.T.sort_values(by = 0, ascending=False)\n",
    "df_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix for above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[113,   0],\n",
       "       [ 14,  99]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted nature</th>\n",
       "      <th>predicted history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual nature</th>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual history</th>\n",
       "      <td>14</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                predicted nature  predicted history\n",
       "actual nature                113                  0\n",
       "actual history                14                 99"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(data=cm, columns=['predicted nature', 'predicted history'], index=['actual nature', 'actual history'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression with CV is very accurate at predicting nature, there are some errors with history; time to look at other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    113\n",
       "0    113\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression with TFIDF - in a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.9601769911504425\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "model = make_pipeline(TfidfVectorizer(stop_words='english'),\n",
    "                      LogisticRegression(),\n",
    "                      )\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print('accuracy score',accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix for TFIDF with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[110,   3],\n",
       "       [  6, 107]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted nature</th>\n",
       "      <th>predicted history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual nature</th>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual history</th>\n",
       "      <td>6</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                predicted nature  predicted history\n",
       "actual nature                110                  3\n",
       "actual history                 6                107"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(data=cm, columns=['predicted nature', 'predicted history'], index=['actual nature', 'actual history'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The accuracy has greatly improved for predicting history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression with CountVectorizer - Same as above but in a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.9380530973451328\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(CountVectorizer(stop_words='english'),LogisticRegression())\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print('accuracy score',accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[113,   0],\n",
       "       [ 14,  99]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted nature</th>\n",
       "      <th>predicted history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual nature</th>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual history</th>\n",
       "      <td>14</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                predicted nature  predicted history\n",
       "actual nature                113                  0\n",
       "actual history                14                 99"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(data=cm, columns=['predicted nature', 'predicted history'], index=['actual nature', 'actual history'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest with CountVectorizer - Gridsearch Params + Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.9026548672566371\n",
      "best cv score 0.8566953797963978\n",
      "test score 0.9026548672566371\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = make_pipeline(CountVectorizer(stop_words='english'),\n",
    "                      RandomForestClassifier(n_estimators= 7, random_state = 42))\n",
    "#params={'n_estimators' : [5, 7, 10]}\n",
    "params={}\n",
    "gs= GridSearchCV(rf_model, param_grid=params)\n",
    "gs.fit(X_train, y_train)\n",
    "y_pred = gs.predict(X_test)\n",
    "#print('best params', gs.best_params_)\n",
    "print('accuracy score',accuracy_score(y_test, y_pred))\n",
    "print('best cv score', gs.best_score_)\n",
    "print('test score', gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our optimum estimators are 7 for Randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[112,   1],\n",
       "       [ 21,  92]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted nature</th>\n",
       "      <th>predicted history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual nature</th>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual history</th>\n",
       "      <td>21</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                predicted nature  predicted history\n",
       "actual nature                112                  1\n",
       "actual history                21                 92"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(data=cm, columns=['predicted nature', 'predicted history'], index=['actual nature', 'actual history'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest with TFIDFVectorizer - Gridsearch Params + Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.9070796460176991\n",
      "best cv score 0.8519968676585747\n",
      "test score 0.9070796460176991\n"
     ]
    }
   ],
   "source": [
    "rf_model_2 = make_pipeline(TfidfVectorizer(stop_words='english'),\n",
    "                      RandomForestClassifier(n_estimators=7, random_state=42))\n",
    "#params={'n_estimators' : [5, 7, 10]}\n",
    "gs1= GridSearchCV(rf_model_2, param_grid=params)\n",
    "gs1.fit(X_train, y_train)\n",
    "y_pred = gs1.predict(X_test)\n",
    "print('accuracy score',accuracy_score(y_test, y_pred))\n",
    "print('best cv score', gs1.best_score_)\n",
    "print('test score', gs1.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[113,   0],\n",
       "       [ 21,  92]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted nature</th>\n",
       "      <th>predicted history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual nature</th>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual history</th>\n",
       "      <td>21</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                predicted nature  predicted history\n",
       "actual nature                113                  0\n",
       "actual history                21                 92"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(data=cm, columns=['predicted nature', 'predicted history'], index=['actual nature', 'actual history'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our TFIDF Random Forest makes a slightly better prediction than Count Vectorizer Random Forest with 0 misclassifications of nature v/s 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM with CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A standard SVM seeks to find a margin that separates all positives and negatives in the class. 'C' is the parameter for the soft margin cost function, which controls the influence of each individual support vector; this process involves trading error penalty for stability.Gamma accounts for the variance (inversely related).A small gamma means a Gaussian with a large variance \n",
    "Using an optimal C = 10.0 and raising the gamma to 0.1 we get our best parameters for SVM Count Vectorizer, For TFIDF C = 1.0 and gamma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = svm.SVC(C = 10.0,\n",
    "              kernel = 'rbf',\n",
    "              gamma = 0.1)\n",
    "svc.fit(X_train_cv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.911504424778761"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[113,   0],\n",
       "       [ 20,  93]], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted nature</th>\n",
       "      <th>predicted history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual nature</th>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual history</th>\n",
       "      <td>20</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                predicted nature  predicted history\n",
       "actual nature                113                  0\n",
       "actual history                20                 93"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(data=cm, columns=['predicted nature', 'predicted history'], index=['actual nature', 'actual history'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = make_pipeline(TfidfVectorizer(stop_words='english'),\n",
    "                      svm.SVC(C = 1,\n",
    "              kernel = 'rbf',\n",
    "              gamma = 1))\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9646017699115044"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[111,   2],\n",
       "       [  6, 107]], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted nature</th>\n",
       "      <th>predicted history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual nature</th>\n",
       "      <td>111</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual history</th>\n",
       "      <td>6</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                predicted nature  predicted history\n",
       "actual nature                111                  2\n",
       "actual history                 6                107"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(data=cm, columns=['predicted nature', 'predicted history'], index=['actual nature', 'actual history'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The SVM and Logistic Regression with TFIDF performs the best among all our models with the highest accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I analyzed and evaluated Reddit's API for predicting a particular subreddit based of text titles/text posts in a given thread.\n",
    "The problem is a binary classification of two subreddits - 1.fakehistoryporn 2.NatureIsFuckingLit\n",
    "To solve the problem, my workflow included three parts:\n",
    "\n",
    "Webscraping: Use requests and json packages to scarpe the above 2 subreddits.\n",
    "NLP and Modelling: Build classification models that are possible to interpret the importance of text(key word) features (e.g. KNN can’t be used) and choose one with a highest test score of accuracy.\n",
    "Inferences: Analyze the result of features (coefficient / key word importance) and find the most important key words that can be used to correctly classify a sub-reddit post and successfully predict a future subreddit post.\n",
    "\n",
    "Here are some findings I got from the classification modeling and the natural language processing:\n",
    "\n",
    "Comparing the TFIDF Vectorizer and Count vectorizer, the TFIDF Vectorizer performs better for the feature dataset which comprises of the title and selftext.Count Vectorizer simplycounts the number of times a token shows up in the document and uses this value as its weight. TFIDF Vectorizer ensures that the weight assigned to each token not only depends on its frequency in a document but also how recurrent that term is in the entire corpus. This is key in removing function words like pronouns which are very common in an opinionated(comment-based) website like Reddit and which should not be a token of high weightage and hence should be weighted down in TFIDF.\n",
    "HashingVectorizer and CountVectorizer return identical results. The difference between HV and CV is that HV does not store the names of features (and thus is more memory efficient) whereas CV keeps the names of features.Hence, HashingVectorizer was not used.\n",
    "\n",
    "Key fakehistoryporn tokens include:\n",
    "colorized, circa, 1944,\tad, hitler, bc, 1943, american, battle, german, nazi, 1939, 1968, soldier, roman, president, army\n",
    "Key NatureIsFuckingLit tokens include:\n",
    "shark, park, kingfisher, iceland, lightning, coast, crab, turtle, wasp, fish, owl, caterpillar, dragonfly, octopus, bird,\t\n",
    "rainbow, nature, sunset, baby,\tspider, tree, beautiful\n",
    "\n",
    "The above makes perfect sense for classifying our data accurately.\n",
    "\n",
    "3 classification models were used for evaluation of the corpus. The Logistic , Random Forest, SVM\n",
    "\n",
    "The Logistic approach we get coefficients that estimate how our independent variables(text features) affect our dependent variable(correct subreddit). It therefore is a very good model to use because the dataset is not very big and the model is not being overwhelmed by many features.\n",
    "The Random Forests model which is a bagging method involving an ensemble of trees is also used for this problem. It performs with very reasonable accuracy by estimating an accurate model by shuffling through the text feature.\n",
    "Using SVM, every text in our dataset is represented as a vector with thousands of dimensions, every one representing the frequency one of the words of the text. It works very well as our dataset is not very robust.The high dimensional features space means it is great model for avoiding overfitting.\n",
    "\n",
    "The Logistic and SVM with TFIDF Vectorizer are our best performers with the highest accuracy of post and subreddit classification - nearly 96% accuracy.\n",
    "\n",
    "Further explorations should incorporate using:\n",
    "A boosting algorithm for classification like Gradient or Ada Boost. \n",
    "Using n-grams to find a phrase instead of a word token for more accurate classification.\n",
    "Collecting more data and grow the corpus and reevaluate the performance of the models especially the performance of the ensemble of trees(bagging and boosting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that a Multinomial Naive Bayes Model works very well with text data, this modelling was performed to test our hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_cv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9513274336283186"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[105,   8],\n",
       "       [  3, 110]], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted nature</th>\n",
       "      <th>predicted history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual nature</th>\n",
       "      <td>105</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual history</th>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                predicted nature  predicted history\n",
       "actual nature                105                  8\n",
       "actual history                 3                110"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(data=cm, columns=['predicted nature', 'predicted history'], index=['actual nature', 'actual history'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_tfidf = make_pipeline(TfidfVectorizer(stop_words='english'),\n",
    "                      nb)\n",
    "nb_tfidf.fit(X_train, y_train)\n",
    "y_pred = nb_tfidf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9513274336283186"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[105,   8],\n",
       "       [  3, 110]], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted nature</th>\n",
       "      <th>predicted history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual nature</th>\n",
       "      <td>105</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual history</th>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                predicted nature  predicted history\n",
       "actual nature                105                  8\n",
       "actual history                 3                110"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(data=cm, columns=['predicted nature', 'predicted history'], index=['actual nature', 'actual history'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that NB model is very accurate in optimizing between the false positives and false negatives for our dataset"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
